{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Neural Networks for Sentimental Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reding the data from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>OK, lets start with the best. the building. al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The British 'heritage film' industry is out of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I don't even know where to begin on this one. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I waited long to watch this movie. Also becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49995  OK, lets start with the best. the building. al...          0\n",
       "49996  The British 'heritage film' industry is out of...          0\n",
       "49997  I don't even know where to begin on this one. ...          0\n",
       "49998  Richard Tyler is a little boy who is scared of...          0\n",
       "49999  I waited long to watch this movie. Also becaus...          1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('shuffled_movie_data.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvaro/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Embedding, SimpleRNN,Bidirectional\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words = 10000\n",
    "tokenizer  = Tokenizer(num_words = num_words)\n",
    "tokenizer.fit_on_texts( df.review )\n",
    "sequences = tokenizer.texts_to_sequences(df.review)\n",
    "y  =  np.array((df.sentiment))\n",
    "y[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences \n",
    "\n",
    "max_review_length = 200\n",
    "\n",
    "pad = 'pre'\n",
    "\n",
    "X = pad_sequences(sequences,max_review_length,padding=pad,truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 200)\n",
      "(10000, 200)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "input_shape = X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 32)           320000    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                16640     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 336,705\n",
      "Trainable params: 336,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "lstm_model = Sequential()\n",
    "# We specify the maximum input length to our Embedding layer\n",
    "# so we can later flatten the embedded inputs\n",
    "lstm_model.add(Embedding(num_words, \n",
    "                        32, \n",
    "                        input_length=max_review_length))\n",
    "\n",
    "lstm_model.add(Bidirectional(LSTM(32)))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.add(Activation('sigmoid'))\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "28000/28000 [==============================] - 35s 1ms/step - loss: 0.4587 - acc: 0.7751 - val_loss: 0.3113 - val_acc: 0.8709\n",
      "Epoch 2/10\n",
      "28000/28000 [==============================] - 34s 1ms/step - loss: 0.2487 - acc: 0.9036 - val_loss: 0.2805 - val_acc: 0.8843\n",
      "Epoch 3/10\n",
      "28000/28000 [==============================] - 35s 1ms/step - loss: 0.1905 - acc: 0.9317 - val_loss: 0.2866 - val_acc: 0.8813\n",
      "Epoch 4/10\n",
      "28000/28000 [==============================] - 37s 1ms/step - loss: 0.1474 - acc: 0.9498 - val_loss: 0.3286 - val_acc: 0.8776\n",
      "Epoch 5/10\n",
      "28000/28000 [==============================] - 39s 1ms/step - loss: 0.1212 - acc: 0.9597 - val_loss: 0.3370 - val_acc: 0.8754\n",
      "Epoch 6/10\n",
      "28000/28000 [==============================] - 39s 1ms/step - loss: 0.1102 - acc: 0.9623 - val_loss: 0.3835 - val_acc: 0.8721\n",
      "Epoch 7/10\n",
      "28000/28000 [==============================] - 42s 2ms/step - loss: 0.0818 - acc: 0.9753 - val_loss: 0.4245 - val_acc: 0.8744\n",
      "Epoch 8/10\n",
      "28000/28000 [==============================] - 42s 1ms/step - loss: 0.0874 - acc: 0.9722 - val_loss: 0.4123 - val_acc: 0.8717\n",
      "Epoch 9/10\n",
      "28000/28000 [==============================] - 39s 1ms/step - loss: 0.0681 - acc: 0.9789 - val_loss: 0.5276 - val_acc: 0.8668\n",
      "Epoch 10/10\n",
      "28000/28000 [==============================] - 39s 1ms/step - loss: 0.0648 - acc: 0.9795 - val_loss: 0.5195 - val_acc: 0.8680\n"
     ]
    }
   ],
   "source": [
    "lstm_model.compile(optimizer=\"adam\", \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "lstm_history = lstm_model.fit(X_train, \n",
    "                              y_train,\n",
    "                              epochs=10,\n",
    "                              batch_size=128,\n",
    "                              validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction fase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000  Iterations will be done.\n",
      "Testeo: 0 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 100 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 200 -> y_pred: [0] -> REAL: 1\n",
      "Testeo: 300 -> y_pred: [1] -> REAL: 0\n",
      "Testeo: 400 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 500 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 600 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 700 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 800 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 900 -> y_pred: [1] -> REAL: 0\n",
      "Testeo: 1000 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 1100 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 1200 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 1300 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 1400 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 1500 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 1600 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 1700 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 1800 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 1900 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 2000 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 2100 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 2200 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 2300 -> y_pred: [0] -> REAL: 1\n",
      "Testeo: 2400 -> y_pred: [1] -> REAL: 0\n",
      "Testeo: 2500 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 2600 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 2700 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 2800 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 2900 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 3000 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 3100 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 3200 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 3300 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 3400 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 3500 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 3600 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 3700 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 3800 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 3900 -> y_pred: [1] -> REAL: 0\n",
      "Testeo: 4000 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 4100 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 4200 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 4300 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 4400 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 4500 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 4600 -> y_pred: [1] -> REAL: 0\n",
      "Testeo: 4700 -> y_pred: [1] -> REAL: 0\n",
      "Testeo: 4800 -> y_pred: [0] -> REAL: 1\n",
      "Testeo: 4900 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 5000 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 5100 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 5200 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 5300 -> y_pred: [1] -> REAL: 0\n",
      "Testeo: 5400 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 5500 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 5600 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 5700 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 5800 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 5900 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 6000 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 6100 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 6200 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 6300 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 6400 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 6500 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 6600 -> y_pred: [1] -> REAL: 0\n",
      "Testeo: 6700 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 6800 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 6900 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 7000 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 7100 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 7200 -> y_pred: [0] -> REAL: 1\n",
      "Testeo: 7300 -> y_pred: [1] -> REAL: 0\n",
      "Testeo: 7400 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 7500 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 7600 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 7700 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 7800 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 7900 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 8000 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 8100 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 8200 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 8300 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 8400 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 8500 -> y_pred: [1] -> REAL: 0\n",
      "Testeo: 8600 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 8700 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 8800 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 8900 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 9000 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 9100 -> y_pred: [1] -> REAL: 0\n",
      "Testeo: 9200 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 9300 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 9400 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 9500 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 9600 -> y_pred: [0] -> REAL: 0\n",
      "Testeo: 9700 -> y_pred: [1] -> REAL: 1\n",
      "Testeo: 9800 -> y_pred: [1] -> REAL: 0\n",
      "Testeo: 9900 -> y_pred: [1] -> REAL: 0\n"
     ]
    }
   ],
   "source": [
    "y_pred=[]\n",
    "print(len(X_test),\" Iterations will be done.\")\n",
    "for i in range(len(X_test)):\n",
    "    result2 = lstm_model.predict(X_test[i].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "    pred=(result2>0.5)*1\n",
    "    y_pred.append(pred)\n",
    "    if i%100==0:\n",
    "        print(\"Testeo:\",i,\"-> y_pred:\",pred,\"-> REAL:\",y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4133  860]\n",
      " [ 529 4478]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "Result=confusion_matrix(y_test, y_pred)\n",
    "print(Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative precision:  0.8277588624073703\n",
      "Positive precision:  0.8943479129219093\n",
      "General precision:  0.8611\n"
     ]
    }
   ],
   "source": [
    "print(\"Negative precision: \",Result[0,0]/(Result[0,0]+Result[0,1]))\n",
    "print(\"Positive precision: \",Result[1,1]/(Result[1,0]+Result[1,1]))\n",
    "print(\"General precision: \",(Result[1,1]+Result[0,0])/(Result[0,0]+Result[0,1]+Result[1,0]+Result[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
